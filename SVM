import os
import re

import tensorflow as tf
import tensorflow.python.platform
from tensorflow.python.platform import gfile
import numpy as np
import pandas as pd
import sklearn
from sklearn import cross_validation
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.svm import SVC, LinearSVC
import matplotlib.pyplot as plt
#matplotlib inline
import pickle
import cv2
import time

#model_dir = 'imagenet'
images_dir = 'images/'
s1 = 's1/'
s2 = 's2/'




'''AUTO = True  # 自动拍照，或手动按s键拍照
INTERVAL = 0.1 # 自动拍照间隔

cv2.namedWindow("take a photo")

cv2.moveWindow("take a photo", 0, 0)

camera = cv2.VideoCapture(1)


counter = 0
utc = time.time()
print (utc)
pattern = (12, 8) # 棋盘格尺寸
folder = "./test/" # 拍照文件目录

def shot(pos, frame):
    global counter
    path = folder + pos + "_" + str(counter) + ".jpg"

    cv2.imwrite(path, frame)
    print("snapshot saved into: " + path)

while True:
    _, frame = camera.read()

    cv2.imshow("take a photo", frame)

    now = time.time()
    if AUTO and now - utc >= INTERVAL:
        shot("take a photo", frame)
        counter += 1
        utc = now

    key = cv2.waitKey(1)
    if key == ord("q") or counter == 49:
        break
    if key == ord("s"):
        shot("take a photo", frame)
        counter += 1

camera.release()
cv2.destroyWindow("take a photo")'''

list_images = [images_dir+f for f in os.listdir(images_dir) if re.search('jpg|JPG', f)]

list_test1 = [s1+f for f in os.listdir(s1) if re.search('jpg|JPG', f)]
list_test2 = [s2+f for f in os.listdir(s2) if re.search('jpg|JPG', f)]

#list_test = sorted(a,key = lambda d:int(d.split('.')[0]))


def create_graph():
    with gfile.FastGFile('retrained_graph_smartphones.pb', 'rb') as f:
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(f.read())
        _ = tf.import_graph_def(graph_def, name='')


def extract_features(list_images,label):
    nb_features = 2048
    features = np.empty((len(list_images),nb_features))
    labels = []

    create_graph()

    with tf.Session() as sess:

        next_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')

        for ind, image in enumerate(list_images):
            if (ind%100 == 0):
                print('Processing %s...' % (image))
                
            if not gfile.Exists(image):
                tf.logging.fatal('File does not exist %s', image)

            image_data = gfile.FastGFile(image, 'rb').read()
            predictions = sess.run(next_to_last_tensor,
            {'DecodeJpeg/contents:0': image_data})
            features[ind,:] = np.squeeze(predictions)
            labels.append(label)

        return features, labels

features,labels = extract_features(list_images, 'autre')
features1, labels1 = extract_features(list_test1, 's1')
features2, labels2 = extract_features(list_test2, 's2')

'''pickle.dump(features, open('features', 'wb'))
pickle.dump(labels, open('labels', 'wb'))

features = pickle.load(open('features',encoding='utf-8'))
labels = pickle.load(open('labels',encoding='utf-8'))'''
X_train = np.concatenate((features1[:30],features2[:30] ,features), axis=0)
y_train = np.concatenate((labels1[:30] ,labels2[:30], labels), axis=0)


X_test = np.concatenate((features1[30:],features2[30:] ,features), axis=0)
y_test =  np.concatenate((labels1[30:] ,labels2[30:], labels), axis=0)
#X_train, X_test, y_train, y_test = cross_validation.train_test_split(features, labels, test_size=0.2, random_state=42)


clf = LinearSVC(C=1.0, loss='squared_hinge', penalty='l2',multi_class='ovr')
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print (y_pred)

print("Accuracy: {0:0.1f}%".format(accuracy_score(y_test,y_pred)*100))

'''def plot_confusion_matrix(y_true,y_pred):
    cm_array = confusion_matrix(y_true,y_pred)
    true_labels = np.unique(y_true)
    pred_labels = np.unique(y_pred)
    plt.imshow(cm_array[:-1,:-1], interpolation='nearest', cmap=plt.cm.Blues)
    plt.title("Confusion matrix", fontsize=16)
    cbar = plt.colorbar(fraction=0.046, pad=0.04)
    cbar.set_label('Number of images', rotation=270, labelpad=30, fontsize=12)
    xtick_marks = np.arange(len(true_labels))
    ytick_marks = np.arange(len(pred_labels))
    plt.xticks(xtick_marks, true_labels, rotation=90)
    plt.yticks(ytick_marks,pred_labels)
    plt.tight_layout()
    plt.ylabel('True label', fontsize=14)
    plt.xlabel('Predicted label', fontsize=14)
    fig_size = plt.rcParams["figure.figsize"]
    fig_size[0] = 12
    fig_size[1] = 12
    plt.rcParams["figure.figsize"] = fig_size


print("Accuracy: {0:0.1f}%".format(accuracy_score(y_test,y_pred)*100))
plot_confusion_matrix(y_test,y_pred)'''
